{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d62776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb181e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = [\n",
    "    'punkt',\n",
    "    'punkt_tab',\n",
    "    'stopwords',\n",
    "    'wordnet',\n",
    "    'omw-1.4',\n",
    "    'averaged_perceptron_tagger_eng'\n",
    "]\n",
    "for item in downloads:\n",
    "    nltk.download(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.api.authenticate()\n",
    "# kaggle.api.dataset_download_files('team-ai/spam-text-message-classification',unzip=True,path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/SPAM text message 20170820 - Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0317eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['Category'].value_counts()\n",
    "ax = sns.barplot(x=counts.index, y=counts.values)\n",
    "\n",
    "total = counts.sum()\n",
    "for i, v in enumerate(counts.values):\n",
    "    ax.text(i, v, f\"{v/total:.1%}\", ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b160315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding the category\n",
    "df['Category'] = df['Category'].map({'ham': 0, 'spam': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a60d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Emoji as in this case (Sentiment analysis) it important\n",
    "emoji_pattern = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
    "    \"\\U0001F700-\\U0001F77F\"\n",
    "    \"\\U0001F780-\\U0001F7FF\"\n",
    "    \"\\U0001F800-\\U0001F8FF\"\n",
    "    \"\\U0001F900-\\U0001F9FF\"\n",
    "    \"\\U0001FA00-\\U0001FAFF\"\n",
    "    \"]+\",\n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "df[\"Message\"].apply(lambda x: bool(emoji_pattern.search(str(x)))).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Emoji is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text and normalizing\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)        # HTML\n",
    "    text = re.sub(r'\\d+', '', text)          # numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)      # punctuation\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # emojis\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54159ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the punctuation mark and lowercasing the msg\n",
    "df['text'] = df['Message'].apply(clean_text)\n",
    "df.drop(columns='Message',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08741473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "df['text'] = df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16697ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].apply(\n",
    "    lambda x: [w for w in x if w.lower() not in stop_words]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_with_pos(tokens):\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    return [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
    "        for word, tag in pos_tags\n",
    "    ]\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatize_with_pos)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed91590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : ' '.join(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550dfde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
